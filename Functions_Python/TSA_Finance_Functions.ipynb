{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce53dce",
   "metadata": {},
   "source": [
    "GLOBAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5dfd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dependecies and libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as smd \n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import beta\n",
    "from arch import arch_model\n",
    "from arch.univariate import ConstantMean, ARX, GARCH, EGARCH, ARCHInMean, StudentsT, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4f51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance function\n",
    "\n",
    "def dist(fit, x, type_):\n",
    "\n",
    "    # Extract distribution name\n",
    "    dist_name = fit.model.modeldesc['distribution']\n",
    "\n",
    "    # Extract parameters with default fallback\n",
    "    lambda_ = fit.fit.coef.get('lambda', -0.5)\n",
    "    skew = fit.fit.coef.get('skew', 1)\n",
    "    shape = fit.fit.coef.get('shape', 1)\n",
    "\n",
    "    # Call custom density or quantile function\n",
    "    if type_ == 'd':\n",
    "        return dist(distribution=dist_name, y=x, mu=0, sigma=1,\n",
    "                     lambda_=lambda_, skew=skew, shape=shape)\n",
    "    elif type_ == 'q':\n",
    "        return dist(distribution=dist_name, p=x, mu=0, sigma=1,\n",
    "                     lambda_=lambda_, skew=skew, shape=shape)\n",
    "    else:\n",
    "        raise ValueError(\"Argument 'type_' must be 'd' or 'q'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219370c4",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    Compute density or quantile of a fitted distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - fit: Fitted model object (must contain fit.coef and model.modeldesc['distribution'])\n",
    "    - x: Value(s) at which to evaluate the function\n",
    "    - type_: 'd' for density, 'q' for quantile\n",
    "\n",
    "    Returns:\n",
    "    - Density or quantile value(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fbc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global histogram options\n",
    "\n",
    "def plot_hist(x, xlim, n=200, bins=100, title=\"\"):\n",
    "\n",
    "    # Histogram\n",
    "    plt.hist(x, bins=bins, density=True, range=xlim, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Normal PDF overlay\n",
    "    x1 = np.linspace(xlim[0], xlim[1], n)\n",
    "    pdf1 = norm.pdf(x1, loc=np.mean(x), scale=np.std(x))\n",
    "    plt.plot(x1, pdf1, color='red', linewidth=2)\n",
    "\n",
    "    # Decorations\n",
    "    plt.title(title)\n",
    "    plt.xlim(xlim)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2665de7",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    Plot histogram of data with overlaid normal PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - x: array-like object, data\n",
    "    - xlim: tuple of (xmin, xmax), x-axis limits\n",
    "    - n: number of points for PDF line\n",
    "    - bins: number of histogram bins\n",
    "    - title: plot title\n",
    "\n",
    "    norm.pdf() is a built-in SciPy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749aa369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global histogram options specifically for model residuals in GARCH\n",
    "\n",
    "def plot_hist_fit(fit, xlim, ylim=None, n=200, bins=100, plot_norm=False, title=\"\"):\n",
    "    \n",
    "    colors = ['red', 'blue'] #change for visual preferences\n",
    "    \n",
    "    # Residuals\n",
    "    z = fit.fit.z\n",
    "\n",
    "    # Histogram\n",
    "    plt.hist(z, bins=bins, density=True, range=xlim, edgecolor='black', alpha=0.7, label='Histogram')\n",
    "    \n",
    "    # Compute fitted PDF\n",
    "    x1 = np.linspace(xlim[0], xlim[1], n)\n",
    "    pdf1 = dist(fit=fit, x=x1, type_='d')\n",
    "    plt.plot(x1, pdf1, color=colors[0], linewidth=2, label=fit.model.modeldesc['Distribution'])\n",
    "\n",
    "    # Optional: add normal PDF\n",
    "    if plot_norm and fit.model.modeldesc['Distribution'] != 'norm':\n",
    "        pdf2 = norm.pdf(x1)\n",
    "        plt.plot(x1, pdf2, color=colors[1], linewidth=2, label='norm')\n",
    "\n",
    "    # Final touches\n",
    "    plt.title(title)\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa024d",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    Plot histogram of model residuals with overlaid fitted and (optional) normal PDFs (Propability Density Functions).\n",
    "\n",
    "    Parameters:\n",
    "    - fit: Fitted model object with residuals in fit.fit.z and distribution in fit.model.modeldesc['distribution']\n",
    "    - xlim: tuple of (xmin, xmax)\n",
    "    - ylim: optional tuple of (ymin, ymax)\n",
    "    - n: number of points to evaluate PDFs\n",
    "    - bins: histogram bins\n",
    "    - plot_norm: boolean, whether to overlay standard normal PDF\n",
    "    - title: plot title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4736f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QQ plot for multivariate distribution\n",
    "\n",
    "def qqplot_fit(fit):\n",
    "    \n",
    "    # Step 1: Sort standardized residuals\n",
    "    zemp = np.sort(fit.fit.z)\n",
    "    n = len(zemp)\n",
    "\n",
    "    # Step 2: Create probabilities\n",
    "    p = np.linspace(1 / (n + 1), n / (n + 1), n)\n",
    "\n",
    "    # Step 3: Get theoretical quantiles from fitted distribution\n",
    "    zth = dist(fit=fit, x=p, type_='q')\n",
    "\n",
    "    # Step 4: Create QQ plot\n",
    "    plt.scatter(zth, zemp, edgecolor='black', facecolor='none')\n",
    "    plt.plot([min(zth), max(zth)], [min(zth), max(zth)], color='red', linewidth=2)  # 45-degree line\n",
    "\n",
    "    plt.xlabel(\"Theoretical quantiles\")\n",
    "    plt.ylabel(\"Empirical quantiles\")\n",
    "    plt.title(\"QQ Plot: Residuals vs. Fitted Distribution\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9c40d",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    QQ plot comparing empirical residuals with theoretical quantiles\n",
    "    from the model's fitted distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - fit: Fitted model object with residuals in fit.fit.z\n",
    "           and distribution in fit.model.modeldesc['distribution']\n",
    "           \n",
    "    We use defined at the beggining .dist() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132dd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating expected value of the absolute value of a standardized residuals \n",
    "\n",
    "def Eabsz(fit):\n",
    "    dist = fit.model.modeldesc['distribution']\n",
    "\n",
    "    if dist == \"norm\":\n",
    "        return np.sqrt(2 / np.pi)\n",
    "    \n",
    "    elif dist == \"std\":\n",
    "        df = float(fit.fit.coef[\"shape\"])\n",
    "        if df <= 2:\n",
    "            return float('nan')  # Undefined\n",
    "        return (2 * np.sqrt(df - 2)) / ((df - 1) * beta(0.5 * df, 0.5))\n",
    "\n",
    "    else:\n",
    "        return f\"Not implemented for distribution '{dist}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944dfe7",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "    \n",
    "    Compute the expected absolute value of standardized residuals\n",
    "    based on the model's assumed distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - fit: Fitted model object with distribution in fit.model.modeldesc['distribution']\n",
    "           and shape parameter in fit.fit.coef['shape'] for t-distribution.\n",
    "           \n",
    "    Returns:\n",
    "    - Expected absolute value (float), or an informative string if unsupported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0922f",
   "metadata": {},
   "source": [
    "GARCH FAMILY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ede202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation of parameters within (GJGARCH, TGARCH) functions\n",
    "\n",
    "def transform_gjr_garch(fit, model_type=\"GJRGARCH\"):\n",
    "    est = fit.params\n",
    "    vcov = fit.covariance\n",
    "\n",
    "    # Updated parameter names for arch package\n",
    "    try:\n",
    "        alpha = est['alpha[1]']\n",
    "        gamma = est['gamma[1]']   # asymmetric effect in arch is named gamma\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Required coefficients 'alpha[1]' or 'gamma[1]' not found in model parameters.\")\n",
    "\n",
    "    # Find indices for these params\n",
    "    alpha_idx = list(est.index).index('alpha[1]')\n",
    "    gamma_idx = list(est.index).index('gamma[1]')\n",
    "\n",
    "    # Apply transformation according to model type\n",
    "    if model_type == \"GJRGARCH\":\n",
    "        alpha_s = alpha * (1 - gamma) ** 2\n",
    "        gamma_s = 4 * alpha * gamma\n",
    "\n",
    "        # Jacobian matrix (derivatives of transformed params wrt original params)\n",
    "        D = np.eye(len(est))\n",
    "        D[alpha_idx, alpha_idx] = (1 - gamma) ** 2\n",
    "        D[alpha_idx, gamma_idx] = -2 * alpha * (1 - gamma)\n",
    "        D[gamma_idx, alpha_idx] = 4 * gamma\n",
    "        D[gamma_idx, gamma_idx] = 4 * alpha\n",
    "\n",
    "    elif model_type == \"TGARCH\":\n",
    "        alpha_s = alpha * (1 - gamma)\n",
    "        gamma_s = 2 * alpha * gamma\n",
    "\n",
    "        D = np.eye(len(est))\n",
    "        D[alpha_idx, alpha_idx] = (1 - gamma)\n",
    "        D[alpha_idx, gamma_idx] = -alpha\n",
    "        D[gamma_idx, alpha_idx] = 2 * gamma\n",
    "        D[gamma_idx, gamma_idx] = 2 * alpha\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type! Use 'GJRGARCH' or 'TGARCH'.\")\n",
    "\n",
    "    # Update estimates vector\n",
    "    est_updated = est.copy()\n",
    "    est_updated.iloc[alpha_idx] = alpha_s\n",
    "    est_updated.iloc[gamma_idx] = gamma_s\n",
    "\n",
    "    # Update covariance matrix\n",
    "    vcov_updated = D @ vcov @ D.T\n",
    "\n",
    "    # Calculate standard errors, t-values, and p-values\n",
    "    se = np.sqrt(np.abs(np.diag(vcov_updated)))\n",
    "    tval = est_updated / se\n",
    "    pval = 2 * (1 - norm.cdf(np.abs(tval)))\n",
    "\n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Estimate\": est_updated,\n",
    "        \"Std. Error\": se,\n",
    "        \"t value\": tval,\n",
    "        \"Pr(>|t|)\": pval\n",
    "    }, index=est.index)\n",
    "\n",
    "    return {\n",
    "        \"coef\": est_updated,\n",
    "        \"se.coef\": se,\n",
    "        \"tval\": tval,\n",
    "        \"pval\": pval,\n",
    "        \"summary\": summary_df,\n",
    "        \"cov\": vcov_updated\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b486b97",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "    \n",
    "    We don't have built-in GJR GARCH function- as a substitute, we will use this one from 'arch' library:\n",
    "    \n",
    "    model = arch_model(\n",
    "    returns,\n",
    "    vol='GARCH',\n",
    "    p=1,\n",
    "    o=1,\n",
    "    q=1,\n",
    "    dist='t',            # Student's t for fat tails\n",
    "    mean='Constant'      # Simple constant mean model\n",
    "    \n",
    "    Purpose of function: Applies the alpha/gamma to alpha_s/gamma_s transformation for GJR-GARCH or TGARCH,\n",
    "    updating coefficient estimates and covariance matrix using the delta method.\n",
    "    \n",
    "    Parameters:\n",
    "    - fit: A fitted GARCH model from `arch` library\n",
    "    - model_type: 'GJRGARCH' or 'TGARCH' (default is 'GJRGARCH')\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with transformed coefficients, standard errors, t-stats, p-values, and covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd3e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garman-Klass volatility estimator (used for intraday data)\n",
    "\n",
    "def garman_klass(data: pd.DataFrame, sd: bool = True, currency: bool = False) -> np.ndarray:\n",
    "    nobs = len(data)\n",
    "    coef = data['Adjusted'] / data['Close']\n",
    "\n",
    "    # Log prices adjusted\n",
    "    H1 = np.log(data['High'] * coef)\n",
    "    L1 = np.log(data['Low'] * coef)\n",
    "    O1 = np.log(data['Open'] * coef)\n",
    "    C1 = np.log(data['Close'] * coef)\n",
    "\n",
    "    u1 = H1 - O1\n",
    "    d1 = L1 - O1\n",
    "    c1 = C1 - O1\n",
    "\n",
    "    # Garman-Klass formula components\n",
    "    x = 0.511 * (u1 - d1) ** 2 + \\\n",
    "        (-0.019) * (c1 * (u1 + d1) - 2 * u1 * d1) + \\\n",
    "        (-0.383) * c1 ** 2\n",
    "\n",
    "    if not currency:\n",
    "        # Overnight returns\n",
    "        retco = np.log(data['Open'][1:].values / data['Close'][:-1].values)\n",
    "        retco = np.insert(retco, 0, np.nan)  # prepend NaN to align length\n",
    "        retoc = np.log(data['Close'] / data['Open'])\n",
    "\n",
    "        x1 = np.nansum(retco ** 2)\n",
    "        x2 = np.nansum(retoc ** 2)\n",
    "\n",
    "        f = x1 / (x1 + x2)\n",
    "        f = np.clip(f, 0.01, 0.99)  # clip between 0.01 and 0.99\n",
    "\n",
    "        a = 0.12\n",
    "        x = a * (retco ** 2) / f + ((1 - a) / (1 - f)) * x\n",
    "\n",
    "    if sd:\n",
    "        return 1.034 * np.sqrt(x)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd772bb",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    Calculate the Garman-Klass volatility estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame with columns ['Open', 'High', 'Low', 'Close', 'Adjusted'] (input in yfinance form)\n",
    "    - sd: If True (default), return volatility (std dev), else return variance estimate.\n",
    "    - currency: If True, skip overnight adjustment (default False).\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray of Garman-Klass volatility estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd530816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified predict function (instead of .forecast())\n",
    "\n",
    "def garch_predict(fit, n_ahead, t, data=None, fixed_n_ahead=True, alpha=None):\n",
    "    \n",
    "    # Use original data if no new data provided\n",
    "    if data is None:\n",
    "        y = fit._y  # original returns used for fitting (numpy array)\n",
    "    else:\n",
    "        y = np.asarray(data)\n",
    "    \n",
    "    nobs = len(y)\n",
    "    if n_ahead <= 0:\n",
    "        raise ValueError(\"Argument 'n_ahead' must be a positive integer\")\n",
    "    if t > nobs:\n",
    "        raise ValueError(\"Argument 't' must be <= length of data\")\n",
    "    if alpha is not None and alpha >= 0.5:\n",
    "        raise ValueError(\"Argument 'alpha' must be lower than 0.5\")\n",
    "    \n",
    "    n_ahead = int(round(n_ahead))\n",
    "\n",
    "    # Refit model if new data is given and t < nobs, else use original fit\n",
    "    # arch does not have direct fixed spec setting like rugarch, so we refit or use original\n",
    "    if data is not None and len(data) > len(fit._y):\n",
    "        # Fit model on new data for rolling forecast\n",
    "        # To speed up, you could pass initial params, but arch does not natively support fixed params\n",
    "        model = arch_model(y, vol=fit.model.volatility.__class__.__name__,\n",
    "                           p=fit.model.p, o=fit.model.o, q=fit.model.q,\n",
    "                           dist=fit.model.distribution.name, mean=fit.model.mean.__class__.__name__)\n",
    "        fit = model.fit(disp=\"off\")\n",
    "    \n",
    "    # Forecast horizon logic\n",
    "    if fixed_n_ahead:\n",
    "        # Forecast fixed horizon starting at t\n",
    "        # arch's forecast function does not allow arbitrary start time,\n",
    "        # so we slice data up to t and forecast n_ahead steps\n",
    "        fit_rolling = fit\n",
    "        # If t < nobs, refit on data up to t\n",
    "        if t < nobs:\n",
    "            fit_rolling = fit.model.fit(y[:t], disp='off')\n",
    "        forecast = fit_rolling.forecast(horizon=n_ahead, reindex=False)\n",
    "        pred_index = np.arange(t, t + n_ahead)\n",
    "        mu = forecast.mean.values[-1, :]  # last row is horizon n_ahead\n",
    "        sigma = np.sqrt(forecast.variance.values[-1, :])\n",
    "        # arch does not provide direct quantiles, so compute if alpha is given using normal approx\n",
    "        if alpha is not None:\n",
    "            z = abs(norm.ppf(alpha / 2))\n",
    "            left = mu - z * sigma\n",
    "            right = mu + z * sigma\n",
    "\n",
    "    else:\n",
    "        # Rolling forecast: forecast 1 step ahead from t until end of series\n",
    "        # arch supports rolling forecast via reindex but limited - so loop forecast\n",
    "        mu = []\n",
    "        sigma = []\n",
    "        pred_index = np.arange(t, nobs)\n",
    "        for i in range(t, nobs):\n",
    "            fit_rolling = fit.model.fit(y[:i], disp='off')\n",
    "            forecast = fit_rolling.forecast(horizon=1, reindex=False)\n",
    "            mu.append(forecast.mean.values[-1, 0])\n",
    "            sigma.append(np.sqrt(forecast.variance.values[-1, 0]))\n",
    "        mu = np.array(mu)\n",
    "        sigma = np.array(sigma)\n",
    "        if alpha is not None:\n",
    "            z = abs(norm.ppf(alpha / 2))\n",
    "            left = mu - z * sigma\n",
    "            right = mu + z * sigma\n",
    "    \n",
    "    # Prepare output dataframe\n",
    "    pred_dict = {\n",
    "        't': pred_index,\n",
    "        'pred': mu,\n",
    "        'se': sigma\n",
    "    }\n",
    "    if alpha is not None:\n",
    "        pred_dict['left'] = left\n",
    "        pred_dict['right'] = right\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred_dict)\n",
    "    \n",
    "    return {\n",
    "        'n_ahead': n_ahead,\n",
    "        'fixed_n_ahead': fixed_n_ahead,\n",
    "        'alpha': alpha,\n",
    "        'pred': pred_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb763803",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "    \n",
    "    Forecast from a fitted arch_model object.\n",
    "    \n",
    "    Parameters:\n",
    "    - fit: Fitted arch_model result (arch.univariate.base.ARCHModelResult)\n",
    "    - n_ahead: Number of steps ahead to forecast (positive int)\n",
    "    - t: Time index to start forecasting (int, <= len(data))\n",
    "    - data: Optional new dataset (pd.Series or np.array), must be longer than fit.data\n",
    "    - fixed_n_ahead: Boolean, if True forecast horizon is fixed, else rolling forecast\n",
    "    - alpha: Significance level for confidence intervals (e.g., 0.05 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "    - dict with keys: 'n_ahead', 'fixed_n_ahead', 'alpha', 'pred' (pd.DataFrame)\n",
    "      pred dataframe columns: ['t', 'pred', 'se', ('left', 'right') if alpha is set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeb3087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized ADF function \n",
    "\n",
    "def adf_test(series, max_aug=10, version='n'):\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    y = series.diff()\n",
    "    X = pd.DataFrame({'y_lag': series.shift()})\n",
    "\n",
    "    if version == 'c' or version == 't': # constant to be added optionally \n",
    "        X = sm.add_constant(X)\n",
    "    if version == 't': # (deterministic) trend component to be added optionally\n",
    "        X['trend'] = range(len(X))\n",
    "\n",
    "    for i in range(0, max_aug): # iterating through different numbers of augmentations\n",
    "        \n",
    "        for aug in range(1, i+1): # adding augmentations one by one until its current amount is reached\n",
    "            X['aug_'+str(aug)] = y.shift(aug)\n",
    "\n",
    "        model = sm.OLS(series.diff(), X, missing='drop').fit() # fitting a linear regression with OLS\n",
    "\n",
    "        ts = model.tvalues['y_lag'] # test statistic\n",
    "        nobs = model.nobs # number of observations\n",
    "\n",
    "        if version == 'n': # critical values for basic version of ADF\n",
    "            if nobs > 500:\n",
    "                cv1 = -2.567; cv5 = -1.941; cv10 = -1.616 # critical values for more than 500 observations\n",
    "            else:\n",
    "                cv1 = np.nan; cv5 = np.nan; cv10 = np.nan # if number of observations is lower than 500, we should check the critical values manually\n",
    "        if version == 'c': # critical values for version with constant\n",
    "            if nobs > 500:\n",
    "                cv1 = -3.434; cv5 = -2.863; cv10 = -2.568 # critical values for more than 500 observations\n",
    "            else:\n",
    "                cv1 = np.nan; cv5 = np.nan; cv10 = np.nan # if number of observations is lower than 500, we should check the critical values manually\n",
    "        if version == 't': # critical values for version with constant and (deterministic) trend component\n",
    "            if nobs > 500:\n",
    "                cv1 = -3.963; cv5 = -3.413; cv10 = -3.128 # critical values for more than 500 observations\n",
    "            else:\n",
    "                cv1 = np.nan; cv5 = np.nan; cv10 = np.nan # if number of observations is lower than 500, we should check the critical values manually\n",
    "\n",
    "        bg_test5 = smd.acorr_breusch_godfrey(model, nlags=5); bg_pvalue5 = round(bg_test5[1],4)\n",
    "        bg_test5 = smd.acorr_breusch_godfrey(model, nlags=10); bg_pvalue10 = round(bg_test5[1],4)\n",
    "        bg_test5 = smd.acorr_breusch_godfrey(model, nlags=15); bg_pvalue15 = round(bg_test5[1],4)\n",
    "\n",
    "        results.append([i, ts, cv1, cv5, cv10, bg_pvalue5, bg_pvalue10, bg_pvalue15])\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.columns = ['number of augmentations', 'ADF test statistic', 'ADF critival value (1%)', 'ADF critival value (5%)', 'ADF critival value (10%)', 'BG test (5 lags) (p-value)', 'BG test (10 lags) (p-value)', 'BG test (15 lags) (p-value)']\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f772b",
   "metadata": {},
   "source": [
    "Additional comments to the function:\n",
    "\n",
    "    This function was developped for the purpose of the Time-Series Analysis labs. Customized function that performs Augmented Dickey-Fuller (ADF) unit root test for a time series, iterating over a range of lag values (augmentations). It optionally includes a constant or trend component and returns test statistics alongside         critical values and Breusch-Godfrey test p-values for autocorrelation in residuals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
